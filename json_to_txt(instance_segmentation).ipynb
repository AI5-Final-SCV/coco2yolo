{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420893f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_list 확인하는 코드\n",
    "import math \n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    " \n",
    "path = \"./annotations_smartinside_segmentation/\" # annotation(json)이 있는 경로\n",
    "file_list = os.listdir(path) # 해당 경로의 모든 파일을 리스트로 받기\n",
    " \n",
    "path3 = \"./dataset_hair_new_smartinside_segmentation/\" # 원본 jpg데이터가 있는 폴더 경로\n",
    "path4 = \"./new_bbox_smartinside_segmentation/\" # 새로운 라벨링(txt)데이터가 저장되는 경로\n",
    "file_list2 = os.listdir(path3) # 지정 폴더안 원본 jpg파일들을 리스트로\n",
    "\n",
    "category_list = [] # 원하는 결과를 위한 빈 리스트 생성\n",
    "\n",
    "for line in file_list2: # 모든 라벨링 파일을 한번 훑어봄\n",
    "    filename = os.path.basename(line) # 파일 이름을 변수로 저장\n",
    "    print(filename) # 파일 이름들 출력(생략가능)\n",
    "    img = Image.open(path3 + str(os.path.splitext(filename)[0]) + '.jpg') # 같은 이름을 가진 path3경로에 있는 jpg 파일 열기\n",
    "    \n",
    "    null = None # null이 지정이 안되어있어서 따로 지정\n",
    "    \n",
    "    with open(path+str(os.path.splitext(filename)[0]) + '.json','r', encoding='utf-8-sig') as inf: # path경로에 있는 모든 json 파일을 열기\n",
    "        obj = eval(inf.read())\n",
    "    x = obj['annotations'] # json안에 있는 딕셔너리에서 annotation의 value값들을 x에 지정\n",
    "    for i in x:\n",
    "        if i['category'] in category_list: # category_list에 기존 category(object name)이 존재하면 넘김\n",
    "            pass\n",
    "        else:\n",
    "            category_list.append(i['category']) # category_list에 새로운게 발견되면 추가\n",
    "\n",
    "print(category_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c21f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import numpy as np\n",
    "category_list = ['common_tree_level2', 'common_flood damaged area_level2', 'common_flood debris damaged area_level2', 'common_street lamp_level2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22c29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링 json to txt\n",
    "def convert_json(json_dir='./annotations_smartinside_segmentation/', use_segments=True, cls91to80=False): # json 파일들 경로\n",
    "    save_dir = \"./new_bbox_smartinside_segmentation/\" # output directory 저장되는 경로\n",
    "\n",
    "    # Import json\n",
    "    for json_file in sorted(Path(json_dir).resolve().glob('*.json')): # json이 있는 폴더에서 모든 json파일에 대해 하나씩\n",
    "        fn = Path(save_dir)  # folder name, 폴더 이름\n",
    "        with open(json_file) as f: # 하나씩 json을 연다\n",
    "            data = json.load(f) # data 변수에 json내용을 저장\n",
    "\n",
    "        # Create image dict\n",
    "        images = {'%g' % x['id']: x for x in data['images']}\n",
    "        # Create image-annotations dict\n",
    "        imgToAnns = defaultdict(list)\n",
    "        for ann in data['annotations']:\n",
    "            imgToAnns[ann['image_id']].append(ann)\n",
    "\n",
    "        # Write labels file\n",
    "        for img_id, anns in tqdm(imgToAnns.items(), desc=f'Annotations {json_file}'):\n",
    "            img = images['%g' % img_id]\n",
    "            h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            for ann in anns:\n",
    "                if ann['iscrowd']:\n",
    "                    continue\n",
    "                # The COCO box format is [top left x, top left y, width, height]\n",
    "                box = np.array(ann['bbox'], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                box[[0, 2]] /= w  # normalize x\n",
    "                box[[1, 3]] /= h  # normalize y\n",
    "                if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                    continue\n",
    "\n",
    "                cls = category_list.index(ann['category'])  # class\n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                # Segments\n",
    "                if use_segments:\n",
    "                    if len(ann['segmentation']) > 1:\n",
    "                        s = merge_multi_segment(ann['segmentation'])\n",
    "                        s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    else:\n",
    "                        s = [j for i in ann['segmentation'] for j in i]  # all segments concatenated\n",
    "                        s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    s = [cls] + s\n",
    "                    if s not in segments:\n",
    "                        segments.append(s)\n",
    "\n",
    "            # Write\n",
    "            with open((fn / f).with_suffix('.txt'), 'a') as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    line = *(segments[i] if use_segments else bboxes[i]),  # cls, box or segments\n",
    "                    file.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "\n",
    "def min_index(arr1, arr2):\n",
    "    \"\"\"Find a pair of indexes with the shortest distance. \n",
    "    Args:\n",
    "        arr1: (N, 2).\n",
    "        arr2: (M, 2).\n",
    "    Return:\n",
    "        a pair of indexes(tuple).\n",
    "    \"\"\"\n",
    "    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)\n",
    "    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img사이즈 640x640으로 변경하는 코드\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "jpg_dir = \"./dataset_hair_new_smartinside_segmentation/\"\n",
    "save_dir = \"./dataset_resized_smartinside_segmentation(640x640)/\"\n",
    "dirs = os.listdir(jpg_dir)\n",
    "\n",
    "for file in dirs:\n",
    "    if os.path.isfile(jpg_dir+file):  #파일인지 아닌지 체크하기위함!\n",
    "        img = cv2.imread(jpg_dir+file) # 이미지 읽기\n",
    "        img_resized = cv2.resize(img, (640, 640)) #size 지정. 따로 변수를 빼는것도 나쁘지 않겠네요.\n",
    "        cv2.imwrite(save_dir+file, img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8854b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test validation 으로 나누는 코드\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 원본 파일과 라벨링 데이터의 경로\n",
    "jpg_folder = \"./dataset_resized_smartinside_segmentation(640x640)/\"\n",
    "txt_folder = \"./new_bbox_smartinside_segmentation/\"\n",
    "\n",
    "# 분할된 데이터를 저장할 폴더 경로\n",
    "train_img_folder = \"./datasets/train/images\"\n",
    "train_txt_folder = \"./datasets/train/labels\"\n",
    "test_img_folder = \"./datasets/test/images\"\n",
    "test_txt_folder = \"./datasets/test/labels\"\n",
    "valid_img_folder = \"./datasets/valid/images\"\n",
    "valid_txt_folder = \"./datasets/valid/labels\"\n",
    "\n",
    "# 분할 비율 (train:test:valid)\n",
    "split_ratio = [0.7, 0.1, 0.2]\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "jpg_files = os.listdir(jpg_folder)\n",
    "txt_files = os.listdir(txt_folder)\n",
    "\n",
    "# 파일 목록을 랜덤하게 섞음\n",
    "random.shuffle(jpg_files)\n",
    "\n",
    "# 파일 분할 인덱스 계산\n",
    "num_files = len(jpg_files)\n",
    "train_split = int(num_files * split_ratio[0])\n",
    "test_split = int(num_files * (split_ratio[0] + split_ratio[1]))\n",
    "\n",
    "# train 폴더로 파일 이동\n",
    "for file in jpg_files[:train_split]:\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    txt_file = base_name + \".txt\"\n",
    "    if txt_file in txt_files:\n",
    "        shutil.move(os.path.join(jpg_folder, file), os.path.join(train_img_folder, file))\n",
    "        shutil.move(os.path.join(txt_folder, txt_file), os.path.join(train_txt_folder, txt_file))\n",
    "\n",
    "# test 폴더로 파일 이동\n",
    "for file in jpg_files[train_split:test_split]:\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    txt_file = base_name + \".txt\"\n",
    "    if txt_file in txt_files:\n",
    "        shutil.move(os.path.join(jpg_folder, file), os.path.join(test_img_folder, file))\n",
    "        shutil.move(os.path.join(txt_folder, txt_file), os.path.join(test_txt_folder, txt_file))\n",
    "\n",
    "# valid 폴더로 파일 이동\n",
    "for file in jpg_files[test_split:]:\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    txt_file = base_name + \".txt\"\n",
    "    if txt_file in txt_files:\n",
    "        shutil.move(os.path.join(jpg_folder, file), os.path.join(valid_img_folder, file))\n",
    "        shutil.move(os.path.join(txt_folder, txt_file), os.path.join(valid_txt_folder, txt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3297a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
